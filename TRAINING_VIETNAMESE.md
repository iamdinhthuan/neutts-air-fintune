# üáªüá≥ H∆Ø·ªöNG D·∫™N FINETUNE NEUTTS-AIR CHO TI·∫æNG VI·ªÜT

## üìã M·ª§C L·ª§C
1. [Gi·ªõi thi·ªáu](#gi·ªõi-thi·ªáu)
2. [Y√™u c·∫ßu h·ªá th·ªëng](#y√™u-c·∫ßu-h·ªá-th·ªëng)
3. [C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng](#c√†i-ƒë·∫∑t-m√¥i-tr∆∞·ªùng)
4. [Chu·∫©n b·ªã d·ªØ li·ªáu](#chu·∫©n-b·ªã-d·ªØ-li·ªáu)
5. [Encode audio](#encode-audio)
6. [Training model](#training-model)
7. [S·ª≠ d·ª•ng model ƒë√£ train](#s·ª≠-d·ª•ng-model-ƒë√£-train)
8. [X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p](#x·ª≠-l√Ω-l·ªói-th∆∞·ªùng-g·∫∑p)

---

## üéØ GI·ªöI THI·ªÜU

NeuTTS-Air l√† m·ªôt Text-to-Speech model d·ª±a tr√™n Qwen2.5 0.5B. Model n√†y h·ªçc c√°ch chuy·ªÉn ƒë·ªïi text (d·∫°ng phoneme) th√†nh speech codes (audio ƒë√£ ƒë∆∞·ª£c encode b·ªüi NeuCodec).

**Quy tr√¨nh ho·∫°t ƒë·ªông:**
```
Text ‚Üí Phonemizer (espeak) ‚Üí Phonemes
Audio WAV ‚Üí NeuCodec Encoder ‚Üí Speech Codes
‚Üí Training: Phonemes ‚Üí Speech Codes
```

---

## üíª Y√äU C·∫¶U H·ªÜ TH·ªêNG

### Ph·∫ßn c·ª©ng
- **GPU**: NVIDIA GPU v·ªõi CUDA (khuy·∫øn ngh·ªã >= 8GB VRAM)
- **RAM**: >= 16GB
- **Disk**: >= 20GB tr·ªëng

### Ph·∫ßn m·ªÅm
- **Python**: 3.10 ho·∫∑c 3.11 (khuy·∫øn ngh·ªã 3.10)
- **CUDA**: 11.8 ho·∫∑c 12.1
- **Git**: ƒê·ªÉ clone repository

---

## üîß C√ÄI ƒê·∫∂T M√îI TR∆Ø·ªúNG

### B∆∞·ªõc 1: T·∫°o m√¥i tr∆∞·ªùng ·∫£o

```bash
# T·∫°o m√¥i tr∆∞·ªùng m·ªõi
python -m venv venv

# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### B∆∞·ªõc 2: C√†i ƒë·∫∑t PyTorch

**Quan tr·ªçng**: C√†i PyTorch tr∆∞·ªõc ti√™n!

```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CPU only (kh√¥ng khuy·∫øn ngh·ªã cho training)
pip install torch torchvision torchaudio
```

### B∆∞·ªõc 3: C√†i ƒë·∫∑t dependencies c∆° b·∫£n

```bash
pip install transformers==4.44.2 datasets accelerate
pip install librosa phonemizer tqdm omegaconf loguru fire
```

### B∆∞·ªõc 4: C√†i ƒë·∫∑t NeuCodec

**‚ö†Ô∏è L∆ØU √ù V·ªÄ DEPENDENCY CONFLICTS:**

Tr√™n Windows, c√≥ th·ªÉ g·∫∑p conflict gi·ªØa `torchao`, `triton`, v√† `transformers`. C√≥ 2 c√°ch x·ª≠ l√Ω:

#### C√°ch 1: C√†i neucodec v√† b·ªè qua dependency errors (Khuy·∫øn ngh·ªã)

```bash
pip install neucodec --no-deps
pip install einops  # dependency c·∫ßn thi·∫øt c·ªßa neucodec
```

#### C√°ch 2: S·ª≠ d·ª•ng pre-encoded data

N·∫øu c√°ch 1 kh√¥ng work, b·∫°n c√≥ th·ªÉ:
1. Encode audio tr√™n m√°y Linux/Colab
2. Copy file `.pkl` v·ªÅ m√°y Windows ƒë·ªÉ train

### B∆∞·ªõc 5: C√†i ƒë·∫∑t espeak-ng (cho phonemizer)

**Windows:**
1. Download t·ª´: https://github.com/espeak-ng/espeak-ng/releases
2. C√†i ƒë·∫∑t v√† th√™m v√†o PATH
3. Ki·ªÉm tra: `espeak-ng --version`

**Linux:**
```bash
sudo apt-get install espeak-ng
```

**Mac:**
```bash
brew install espeak-ng
```

### B∆∞·ªõc 6: Ki·ªÉm tra c√†i ƒë·∫∑t

```python
# Test PyTorch + CUDA
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")

# Test phonemizer
from phonemizer.backend import EspeakBackend
backend = EspeakBackend(language='vi')
print(backend.phonemize(['Xin ch√†o']))

# Test neucodec (n·∫øu ƒë√£ c√†i)
try:
    from neucodec import NeuCodec
    print("NeuCodec OK")
except Exception as e:
    print(f"NeuCodec error: {e}")
```

---

## üìÅ CHU·∫®N B·ªä D·ªÆ LI·ªÜU

### Format d·ªØ li·ªáu

B·∫°n c·∫ßn 2 th·ª©:
1. **File metadata.csv** v·ªõi format:
   ```
   audio|transcript
   audio1.wav|C√¢u ti·∫øng Vi·ªát th·ª© nh·∫•t
   audio2.wav|C√¢u ti·∫øng Vi·ªát th·ª© hai
   ```

2. **Th∆∞ m·ª•c ch·ª©a audio** (v√≠ d·ª•: `wavs/`)
   - Format: WAV, 16kHz, mono
   - ƒê·ªô d√†i: 1-10 gi√¢y m·ªói file
   - Ch·∫•t l∆∞·ª£ng: C√†ng r√µ c√†ng t·ªët

### Ki·ªÉm tra d·ªØ li·ªáu

```python
import pandas as pd
import librosa

# ƒê·ªçc metadata
df = pd.read_csv('metadata.csv', sep='|', names=['audio', 'transcript'])
print(f"T·ªïng s·ªë samples: {len(df)}")
print(df.head())

# Ki·ªÉm tra m·ªôt file audio
audio_path = f"wavs/{df.iloc[0]['audio']}"
y, sr = librosa.load(audio_path, sr=16000)
print(f"Sample rate: {sr}, Duration: {len(y)/sr:.2f}s")
```

---

## üéµ ENCODE AUDIO (T√ôY CH·ªåN)

**‚ö° M·ªöI: B·∫°n KH√îNG C·∫¶N encode tr∆∞·ªõc n·ªØa!**

Script training ƒë√£ h·ªó tr·ª£ **ON-THE-FLY ENCODING** - t·ª± ƒë·ªông encode audio khi training!

### C√°ch 1: ON-THE-FLY Encoding (Khuy·∫øn ngh·ªã) ‚ö°

**∆Øu ƒëi·ªÉm:**
- ‚úÖ Kh√¥ng c·∫ßn ch·∫°y script encode tr∆∞·ªõc
- ‚úÖ Ti·∫øt ki·ªám disk (kh√¥ng t·∫°o file pkl l·ªõn)
- ‚úÖ Linh ho·∫°t - d·ªÖ th√™m/b·ªõt data
- ‚úÖ Ph√π h·ª£p v·ªõi dataset l·ªõn

**C√°ch d√πng:**
```yaml
# finetune_vietnamese_config.yaml
dataset_path: "metadata.csv"
audio_dir: "wavs"
```

Ch·ªâ c·∫ßn c√≥ `metadata.csv` v√† th∆∞ m·ª•c `wavs/` l√† ƒë·ªß!

### C√°ch 2: Pre-encode (T√πy ch·ªçn)

**∆Øu ƒëi·ªÉm:**
- ‚úÖ Training nhanh h∆°n (kh√¥ng c·∫ßn encode m·ªói epoch)
- ‚úÖ Ph√π h·ª£p n·∫øu train nhi·ªÅu l·∫ßn v·ªõi c√πng data

**B∆∞·ªõc 1: Encode audio**
```bash
python prepare_vietnamese_dataset.py \
    --metadata metadata.csv \
    --audio_dir wavs \
    --output vietnamese_dataset.pkl \
    --device cuda  # ho·∫∑c 'cpu' n·∫øu kh√¥ng c√≥ GPU
```

**B∆∞·ªõc 2: C·∫•u h√¨nh**
```yaml
# finetune_vietnamese_config.yaml
dataset_path: "vietnamese_dataset.pkl"
# Kh√¥ng c·∫ßn audio_dir
```

### So s√°nh 2 c√°ch:

| Ti√™u ch√≠ | On-the-fly | Pre-encode |
|----------|------------|------------|
| Disk space | ‚úÖ √çt | ‚ùå Nhi·ªÅu (10-20GB) |
| Setup time | ‚úÖ Nhanh | ‚ùå Ch·∫≠m (c·∫ßn encode tr∆∞·ªõc) |
| Training speed | ‚ö†Ô∏è H∆°i ch·∫≠m | ‚úÖ Nhanh h∆°n |
| Linh ho·∫°t | ‚úÖ Cao | ‚ö†Ô∏è Th·∫•p |
| **Khuy·∫øn ngh·ªã** | **‚úÖ D√πng c√°ch n√†y** | Ch·ªâ khi train nhi·ªÅu l·∫ßn |

---

## üöÄ TRAINING MODEL

### C·∫•u h√¨nh training

File `finetune_vietnamese_config.yaml`:

```yaml
# Model checkpoint
restore_from: "neuphonic/neutts-air"

# Dataset - ON-THE-FLY MODE (Khuy·∫øn ngh·ªã)
dataset_path: "metadata.csv"
audio_dir: "wavs"

# Ho·∫∑c d√πng pre-encoded:
# dataset_path: "vietnamese_dataset.pkl"

# Training hyperparameters
lr: 0.00004
max_steps: 1000  # TƒÉng l√™n 2000-5000 cho dataset l·ªõn
per_device_train_batch_size: 1
warmup_ratio: 0.05

# Logging & Saving
save_root: "./checkpoints"
run_name: "neutts-vietnamese"
logging_steps: 10
save_steps: 100
```

### Ch·∫°y training

**V·ªõi on-the-fly encoding:**
```bash
# ƒê·∫£m b·∫£o c√≥ metadata.csv v√† th∆∞ m·ª•c wavs/
python finetune_vietnamese.py finetune_vietnamese_config.yaml
```

**V·ªõi pre-encoded data:**
```bash
# ƒê·∫£m b·∫£o ƒë√£ ch·∫°y prepare_vietnamese_dataset.py tr∆∞·ªõc
python finetune_vietnamese.py finetune_vietnamese_config.yaml
```

### Theo d√µi training

Training s·∫Ω in ra:
- Loss m·ªói 10 steps
- Checkpoint ƒë∆∞·ª£c l∆∞u m·ªói 100 steps v√†o `./checkpoints/neutts-vietnamese/`

**Th·ªùi gian ∆∞·ªõc t√≠nh:**
- 11 samples (test): ~5-10 ph√∫t
- 1000 samples: ~2-4 gi·ªù (GPU)
- 10000 samples: ~1-2 ng√†y (GPU)

---

## üé§ S·ª¨ D·ª§NG MODEL ƒê√É TRAIN

### Load model

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from phonemizer.backend import EspeakBackend
import torch

# Load model ƒë√£ finetune
model_path = "./checkpoints/neutts-vietnamese/checkpoint-1000"
model = AutoModelForCausalLM.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Phonemizer
g2p = EspeakBackend(language='vi', preserve_punctuation=True, with_stress=True)

# Chuy·ªÉn sang eval mode
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
```

### Sinh audio

```python
def text_to_speech(text):
    # Text ‚Üí Phonemes
    phonemes = g2p.phonemize([text])[0]
    
    # T·∫°o prompt (theo format training)
    prompt = f"<|SPEECH_GENERATION_START|><|TEXT_PROMPT_START|>{phonemes}<|TEXT_PROMPT_END|><|SPEECH_START|>"
    
    # Tokenize
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    
    # Generate
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=1000,
            do_sample=True,
            temperature=0.8,
            top_p=0.9
        )
    
    # Decode codes
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)
    
    # Extract speech codes (c·∫ßn parse t·ª´ generated_text)
    # TODO: Implement code extraction v√† decode v·ªõi NeuCodec
    
    return generated_text

# Test
result = text_to_speech("Xin ch√†o, ƒë√¢y l√† b√†i test ti·∫øng Vi·ªát")
print(result)
```

---

## ‚ö†Ô∏è X·ª¨ L√ù L·ªñI TH∆Ø·ªúNG G·∫∂P

### 1. ImportError: cannot import name 'AttrsDescriptor' from 'triton'

**Nguy√™n nh√¢n**: Conflict gi·ªØa torchao v√† triton tr√™n Windows

**Gi·∫£i ph√°p**:
```bash
# C√†i neucodec kh√¥ng dependencies
pip uninstall torchao triton -y
pip install neucodec --no-deps
pip install einops
```

### 2. ModuleNotFoundError: No module named 'torchao'

**Nguy√™n nh√¢n**: torchtune c·∫ßn torchao

**Gi·∫£i ph√°p**: Encode tr√™n Linux/Colab, copy file `.pkl` v·ªÅ

### 3. espeak-ng not found

**Gi·∫£i ph√°p Windows**:
1. Download: https://github.com/espeak-ng/espeak-ng/releases
2. C√†i ƒë·∫∑t v√†o `C:\Program Files\eSpeak NG`
3. Th√™m v√†o PATH: `C:\Program Files\eSpeak NG`
4. Restart terminal

### 4. CUDA out of memory

**Gi·∫£i ph√°p**:
```yaml
# Gi·∫£m batch size trong config
per_device_train_batch_size: 1
gradient_accumulation_steps: 16  # TƒÉng ƒë·ªÉ b√π batch size nh·ªè
```

### 5. Loss kh√¥ng gi·∫£m

**Ki·ªÉm tra**:
- Dataset c√≥ ƒë·ªß l·ªõn? (>= 100 samples)
- Learning rate c√≥ ph√π h·ª£p? (th·ª≠ 0.00002 - 0.0001)
- Audio quality c√≥ t·ªët?
- Phonemizer c√≥ ho·∫°t ƒë·ªông ƒë√∫ng v·ªõi ti·∫øng Vi·ªát?

---

## üìä TIPS ƒê·ªÇ C·∫¢I THI·ªÜN CH·∫§T L∆Ø·ª¢NG

### 1. D·ªØ li·ªáu
- **S·ªë l∆∞·ª£ng**: >= 1000 samples cho k·∫øt qu·∫£ t·ªët
- **Ch·∫•t l∆∞·ª£ng**: Audio r√µ r√†ng, √≠t noise
- **ƒêa d·∫°ng**: Nhi·ªÅu gi·ªçng, nhi·ªÅu ng·ªØ c·∫£nh kh√°c nhau
- **ƒê·ªô d√†i**: 2-8 gi√¢y m·ªói file l√† t·ªëi ∆∞u

### 2. Training
- **Warmup**: D√πng warmup_steps ƒë·ªÉ model ·ªïn ƒë·ªãnh
- **Learning rate**: B·∫Øt ƒë·∫ßu v·ªõi 0.00004, ƒëi·ªÅu ch·ªânh n·∫øu c·∫ßn
- **Steps**: Train ƒë·ªß l√¢u (1000-5000 steps)
- **Validation**: T√°ch 10% data ƒë·ªÉ validate

### 3. Inference
- **Temperature**: 0.7-0.9 cho t·ª± nhi√™n h∆°n
- **Top-p**: 0.85-0.95
- **Max tokens**: ƒêi·ªÅu ch·ªânh theo ƒë·ªô d√†i c√¢u

---

## üìû H·ªñ TR·ª¢

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Ki·ªÉm tra l·∫°i t·ª´ng b∆∞·ªõc trong h∆∞·ªõng d·∫´n
2. Xem ph·∫ßn "X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p"
3. Ki·ªÉm tra log chi ti·∫øt khi ch·∫°y script

---

## üìù CHANGELOG

- **v1.0**: H∆∞·ªõng d·∫´n ban ƒë·∫ßu cho ti·∫øng Vi·ªát
- H·ªó tr·ª£ Windows/Linux/Mac
- X·ª≠ l√Ω dependency conflicts
- Test v·ªõi 11 samples

---

**Ch√∫c b·∫°n training th√†nh c√¥ng! üéâ**

