# ğŸ‡»ğŸ‡³ HÆ¯á»šNG DáºªN FINETUNE NEUTTS-AIR CHO TIáº¾NG VIá»†T

## ğŸ“‹ Má»¤C Lá»¤C
1. [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
2. [YÃªu cáº§u há»‡ thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
3. [CÃ i Ä‘áº·t mÃ´i trÆ°á»ng](#cÃ i-Ä‘áº·t-mÃ´i-trÆ°á»ng)
4. [Chuáº©n bá»‹ dá»¯ liá»‡u](#chuáº©n-bá»‹-dá»¯-liá»‡u)
5. [Encode audio](#encode-audio)
6. [Training model](#training-model)
7. [Sá»­ dá»¥ng model Ä‘Ã£ train](#sá»­-dá»¥ng-model-Ä‘Ã£-train)
8. [Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p](#xá»­-lÃ½-lá»—i-thÆ°á»ng-gáº·p)

---

## ğŸ¯ GIá»šI THIá»†U

NeuTTS-Air lÃ  má»™t Text-to-Speech model dá»±a trÃªn Qwen2.5 0.5B. Model nÃ y há»c cÃ¡ch chuyá»ƒn Ä‘á»•i text (dáº¡ng phoneme) thÃ nh speech codes (audio Ä‘Ã£ Ä‘Æ°á»£c encode bá»Ÿi NeuCodec).

**Quy trÃ¬nh hoáº¡t Ä‘á»™ng:**
```
Text â†’ Phonemizer (espeak) â†’ Phonemes
Audio WAV â†’ NeuCodec Encoder â†’ Speech Codes
â†’ Training: Phonemes â†’ Speech Codes
```

---

## ğŸ’» YÃŠU Cáº¦U Há»† THá»NG

### Pháº§n cá»©ng
- **GPU**: NVIDIA GPU vá»›i CUDA (khuyáº¿n nghá»‹ >= 8GB VRAM)
- **RAM**: >= 16GB
- **Disk**: >= 20GB trá»‘ng

### Pháº§n má»m
- **Python**: 3.10 hoáº·c 3.11 (khuyáº¿n nghá»‹ 3.10)
- **CUDA**: 11.8 hoáº·c 12.1
- **Git**: Äá»ƒ clone repository

---

## ğŸ”§ CÃ€I Äáº¶T MÃ”I TRÆ¯á»œNG

### BÆ°á»›c 1: Táº¡o mÃ´i trÆ°á»ng áº£o

```bash
# Táº¡o mÃ´i trÆ°á»ng má»›i
python -m venv venv

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### BÆ°á»›c 2: CÃ i Ä‘áº·t PyTorch

**Quan trá»ng**: CÃ i PyTorch trÆ°á»›c tiÃªn!

```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CPU only (khÃ´ng khuyáº¿n nghá»‹ cho training)
pip install torch torchvision torchaudio
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies cÆ¡ báº£n

```bash
pip install transformers==4.44.2 datasets accelerate
pip install librosa phonemizer tqdm omegaconf loguru fire
```

### BÆ°á»›c 4: CÃ i Ä‘áº·t NeuCodec

**âš ï¸ LÆ¯U Ã Vá»€ DEPENDENCY CONFLICTS:**

TrÃªn Windows, cÃ³ thá»ƒ gáº·p conflict giá»¯a `torchao`, `triton`, vÃ  `transformers`. CÃ³ 2 cÃ¡ch xá»­ lÃ½:

#### CÃ¡ch 1: CÃ i neucodec vÃ  bá» qua dependency errors (Khuyáº¿n nghá»‹)

```bash
pip install neucodec --no-deps
pip install einops  # dependency cáº§n thiáº¿t cá»§a neucodec
```

#### CÃ¡ch 2: Sá»­ dá»¥ng pre-encoded data

Náº¿u cÃ¡ch 1 khÃ´ng work, báº¡n cÃ³ thá»ƒ:
1. Encode audio trÃªn mÃ¡y Linux/Colab
2. Copy file `.pkl` vá» mÃ¡y Windows Ä‘á»ƒ train

### BÆ°á»›c 5: CÃ i Ä‘áº·t espeak-ng (cho phonemizer)

**Windows:**
1. Download tá»«: https://github.com/espeak-ng/espeak-ng/releases
2. CÃ i Ä‘áº·t vÃ  thÃªm vÃ o PATH
3. Kiá»ƒm tra: `espeak-ng --version`

**Linux:**
```bash
sudo apt-get install espeak-ng
```

**Mac:**
```bash
brew install espeak-ng
```

### BÆ°á»›c 6: Kiá»ƒm tra cÃ i Ä‘áº·t

```python
# Test PyTorch + CUDA
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")

# Test phonemizer
from phonemizer.backend import EspeakBackend
backend = EspeakBackend(language='vi')
print(backend.phonemize(['Xin chÃ o']))

# Test neucodec (náº¿u Ä‘Ã£ cÃ i)
try:
    from neucodec import NeuCodec
    print("NeuCodec OK")
except Exception as e:
    print(f"NeuCodec error: {e}")
```

---

## ğŸ“ CHUáº¨N Bá»Š Dá»® LIá»†U

### Format dá»¯ liá»‡u

Báº¡n cáº§n 2 thá»©:
1. **File metadata.csv** vá»›i format:
   ```
   audio|transcript
   audio1.wav|CÃ¢u tiáº¿ng Viá»‡t thá»© nháº¥t
   audio2.wav|CÃ¢u tiáº¿ng Viá»‡t thá»© hai
   ```

2. **ThÆ° má»¥c chá»©a audio** (vÃ­ dá»¥: `wavs/`)
   - Format: WAV, 16kHz, mono
   - Äá»™ dÃ i: 1-10 giÃ¢y má»—i file
   - Cháº¥t lÆ°á»£ng: CÃ ng rÃµ cÃ ng tá»‘t

### Kiá»ƒm tra dá»¯ liá»‡u

```python
import pandas as pd
import librosa

# Äá»c metadata
df = pd.read_csv('metadata.csv', sep='|', names=['audio', 'transcript'])
print(f"Tá»•ng sá»‘ samples: {len(df)}")
print(df.head())

# Kiá»ƒm tra má»™t file audio
audio_path = f"wavs/{df.iloc[0]['audio']}"
y, sr = librosa.load(audio_path, sr=16000)
print(f"Sample rate: {sr}, Duration: {len(y)/sr:.2f}s")
```

---

## ğŸµ ENCODE AUDIO (TÃ™Y CHá»ŒN)

**âš¡ Má»šI: Báº¡n KHÃ”NG Cáº¦N encode trÆ°á»›c ná»¯a!**

Script training Ä‘Ã£ há»— trá»£ **ON-THE-FLY ENCODING** - tá»± Ä‘á»™ng encode audio khi training!

### CÃ¡ch 1: ON-THE-FLY Encoding (Khuyáº¿n nghá»‹) âš¡

**Æ¯u Ä‘iá»ƒm:**
- âœ… KhÃ´ng cáº§n cháº¡y script encode trÆ°á»›c
- âœ… Tiáº¿t kiá»‡m disk (khÃ´ng táº¡o file pkl lá»›n)
- âœ… Linh hoáº¡t - dá»… thÃªm/bá»›t data
- âœ… PhÃ¹ há»£p vá»›i dataset lá»›n

**CÃ¡ch dÃ¹ng:**
```yaml
# finetune_vietnamese_config.yaml
dataset_path: "metadata.csv"
audio_dir: "wavs"
```

Chá»‰ cáº§n cÃ³ `metadata.csv` vÃ  thÆ° má»¥c `wavs/` lÃ  Ä‘á»§!

### CÃ¡ch 2: Pre-encode (TÃ¹y chá»n)

**Æ¯u Ä‘iá»ƒm:**
- âœ… Training nhanh hÆ¡n (khÃ´ng cáº§n encode má»—i epoch)
- âœ… PhÃ¹ há»£p náº¿u train nhiá»u láº§n vá»›i cÃ¹ng data

**BÆ°á»›c 1: Encode audio**
```bash
python prepare_vietnamese_dataset.py \
    --metadata metadata.csv \
    --audio_dir wavs \
    --output vietnamese_dataset.pkl \
    --device cuda  # hoáº·c 'cpu' náº¿u khÃ´ng cÃ³ GPU
```

**BÆ°á»›c 2: Cáº¥u hÃ¬nh**
```yaml
# finetune_vietnamese_config.yaml
dataset_path: "vietnamese_dataset.pkl"
# KhÃ´ng cáº§n audio_dir
```

### So sÃ¡nh 2 cÃ¡ch:

| TiÃªu chÃ­ | On-the-fly | Pre-encode |
|----------|------------|------------|
| Disk space | âœ… Ãt | âŒ Nhiá»u (10-20GB) |
| Setup time | âœ… Nhanh | âŒ Cháº­m (cáº§n encode trÆ°á»›c) |
| Training speed | âš ï¸ HÆ¡i cháº­m | âœ… Nhanh hÆ¡n |
| Linh hoáº¡t | âœ… Cao | âš ï¸ Tháº¥p |
| **Khuyáº¿n nghá»‹** | **âœ… DÃ¹ng cÃ¡ch nÃ y** | Chá»‰ khi train nhiá»u láº§n |

---

## ğŸš€ TRAINING MODEL

### Cáº¥u hÃ¬nh training

File `finetune_vietnamese_config.yaml`:

```yaml
# Model checkpoint
restore_from: "neuphonic/neutts-air"

# Dataset - ON-THE-FLY MODE (Khuyáº¿n nghá»‹)
dataset_path: "metadata.csv"
audio_dir: "wavs"

# Hoáº·c dÃ¹ng pre-encoded:
# dataset_path: "vietnamese_dataset.pkl"

# Training hyperparameters
lr: 0.00004
max_steps: 1000  # TÄƒng lÃªn 2000-5000 cho dataset lá»›n
per_device_train_batch_size: 1
warmup_ratio: 0.05

# Logging & Saving
save_root: "./checkpoints"
run_name: "neutts-vietnamese"
logging_steps: 10
save_steps: 100
```

### Cháº¡y training

**Vá»›i on-the-fly encoding:**
```bash
# Äáº£m báº£o cÃ³ metadata.csv vÃ  thÆ° má»¥c wavs/
python finetune_vietnamese.py finetune_vietnamese_config.yaml
```

**Vá»›i pre-encoded data:**
```bash
# Äáº£m báº£o Ä‘Ã£ cháº¡y prepare_vietnamese_dataset.py trÆ°á»›c
python finetune_vietnamese.py finetune_vietnamese_config.yaml
```

### Theo dÃµi training

Training sáº½ in ra:
- Loss má»—i 10 steps
- Checkpoint Ä‘Æ°á»£c lÆ°u má»—i 100 steps vÃ o `./checkpoints/neutts-vietnamese/`

**Thá»i gian Æ°á»›c tÃ­nh:**
- 11 samples (test): ~5-10 phÃºt
- 1000 samples: ~2-4 giá» (GPU)
- 10000 samples: ~1-2 ngÃ y (GPU)

---

## ğŸ¤ Sá»¬ Dá»¤NG MODEL ÄÃƒ TRAIN

### Load model

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from phonemizer.backend import EspeakBackend
import torch

# Load model Ä‘Ã£ finetune
model_path = "./checkpoints/neutts-vietnamese/checkpoint-1000"
model = AutoModelForCausalLM.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Phonemizer
g2p = EspeakBackend(language='vi', preserve_punctuation=True, with_stress=True)

# Chuyá»ƒn sang eval mode
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
```

### Sinh audio

```python
def text_to_speech(text):
    # Text â†’ Phonemes
    phonemes = g2p.phonemize([text])[0]
    
    # Táº¡o prompt (theo format training)
    prompt = f"<|SPEECH_GENERATION_START|><|TEXT_PROMPT_START|>{phonemes}<|TEXT_PROMPT_END|><|SPEECH_START|>"
    
    # Tokenize
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    
    # Generate
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=1000,
            do_sample=True,
            temperature=0.8,
            top_p=0.9
        )
    
    # Decode codes
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)
    
    # Extract speech codes (cáº§n parse tá»« generated_text)
    # TODO: Implement code extraction vÃ  decode vá»›i NeuCodec
    
    return generated_text

# Test
result = text_to_speech("Xin chÃ o, Ä‘Ã¢y lÃ  bÃ i test tiáº¿ng Viá»‡t")
print(result)
```

---

## âš ï¸ Xá»¬ LÃ Lá»–I THÆ¯á»œNG Gáº¶P

### 1. ImportError: cannot import name 'AttrsDescriptor' from 'triton'

**NguyÃªn nhÃ¢n**: Conflict giá»¯a torchao vÃ  triton trÃªn Windows

**Giáº£i phÃ¡p**:
```bash
# CÃ i neucodec khÃ´ng dependencies
pip uninstall torchao triton -y
pip install neucodec --no-deps
pip install einops
```

### 2. ModuleNotFoundError: No module named 'torchao'

**NguyÃªn nhÃ¢n**: torchtune cáº§n torchao

**Giáº£i phÃ¡p**: Encode trÃªn Linux/Colab, copy file `.pkl` vá»

### 3. espeak-ng not found

**Giáº£i phÃ¡p Windows**:
1. Download: https://github.com/espeak-ng/espeak-ng/releases
2. CÃ i Ä‘áº·t vÃ o `C:\Program Files\eSpeak NG`
3. ThÃªm vÃ o PATH: `C:\Program Files\eSpeak NG`
4. Restart terminal

### 4. CUDA out of memory

**Giáº£i phÃ¡p**:
```yaml
# Giáº£m batch size trong config
per_device_train_batch_size: 1
gradient_accumulation_steps: 16  # TÄƒng Ä‘á»ƒ bÃ¹ batch size nhá»
```

### 5. Loss khÃ´ng giáº£m

**Kiá»ƒm tra**:
- Dataset cÃ³ Ä‘á»§ lá»›n? (>= 100 samples)
- Learning rate cÃ³ phÃ¹ há»£p? (thá»­ 0.00002 - 0.0001)
- Audio quality cÃ³ tá»‘t?
- Phonemizer cÃ³ hoáº¡t Ä‘á»™ng Ä‘Ãºng vá»›i tiáº¿ng Viá»‡t?

---

## ğŸ“Š TIPS Äá»‚ Cáº¢I THIá»†N CHáº¤T LÆ¯á»¢NG

### 1. Dá»¯ liá»‡u
- **Sá»‘ lÆ°á»£ng**: >= 1000 samples cho káº¿t quáº£ tá»‘t
- **Cháº¥t lÆ°á»£ng**: Audio rÃµ rÃ ng, Ã­t noise
- **Äa dáº¡ng**: Nhiá»u giá»ng, nhiá»u ngá»¯ cáº£nh khÃ¡c nhau
- **Äá»™ dÃ i**: 2-8 giÃ¢y má»—i file lÃ  tá»‘i Æ°u

### 2. Training
- **Warmup**: DÃ¹ng warmup_steps Ä‘á»ƒ model á»•n Ä‘á»‹nh
- **Learning rate**: Báº¯t Ä‘áº§u vá»›i 0.00004, Ä‘iá»u chá»‰nh náº¿u cáº§n
- **Steps**: Train Ä‘á»§ lÃ¢u (1000-5000 steps)
- **Validation**: TÃ¡ch 10% data Ä‘á»ƒ validate

### 3. Inference
- **Temperature**: 0.7-0.9 cho tá»± nhiÃªn hÆ¡n
- **Top-p**: 0.85-0.95
- **Max tokens**: Äiá»u chá»‰nh theo Ä‘á»™ dÃ i cÃ¢u

---

## ğŸ“ Há»– TRá»¢

Náº¿u gáº·p váº¥n Ä‘á»:
1. Kiá»ƒm tra láº¡i tá»«ng bÆ°á»›c trong hÆ°á»›ng dáº«n
2. Xem pháº§n "Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p"
3. Kiá»ƒm tra log chi tiáº¿t khi cháº¡y script

---

## ğŸ“ CHANGELOG

- **v1.0**: HÆ°á»›ng dáº«n ban Ä‘áº§u cho tiáº¿ng Viá»‡t
- Há»— trá»£ Windows/Linux/Mac
- Xá»­ lÃ½ dependency conflicts
- Test vá»›i 11 samples

---

**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸ‰**

